{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKN KG Construction using CSV from Drone data aquisition.\n",
    "\n",
    "> Imagine that you are an agent assistant to a scientist who has some drone data that he wants to publish as a distributed knowledge graph known as an Open Knowledge Network (OKN). The OKN should use known vocabularies (SOSA,OWL-Time,GeoSparql, Prov-o, Dcat) where possible to enable interoperability. The scientist has data in a CSV that are CO2 measurements from a drone flight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Great! To create an Open Knowledge Network (OKN) from the scientist's drone data, we can follow these steps:\n",
    "\n",
    "> Convert the CSV data into a format that is compatible with RDF (Resource Description Framework), which is the foundation of the semantic web. There are various tools available for this, such as OpenRefine or Python libraries like Pandas and RDFlib.\n",
    "\n",
    "> Define the data model using existing ontologies and vocabularies, such as SOSA (Sensor, Observation, Sample, and Actuator), OWL-Time (a vocabulary for expressing dates and times), GeoSparql (a vocabulary for representing geospatial data), Prov-o (a vocabulary for representing provenance information), and Dcat (Data Catalog vocabulary). These ontologies and vocabularies are widely used and well-documented, which makes it easier to achieve interoperability with other knowledge graphs and data sources.\n",
    "\n",
    "> Map the CSV data to the appropriate classes and properties in the defined ontology. For example, the CO2 measurement data could be mapped to the SOSA ontology's Observation class, with properties such as observedProperty (the type of observation being made, in this case CO2 concentration), observedBy (the sensor used to make the observation, in this case the drone), and hasTime (the time at which the observation was made, which can be represented using OWL-Time).\n",
    "\n",
    "> Add provenance information to the data, using the Prov-o ontology. This helps to trace the origin of the data, the process by which it was collected and transformed, and any other relevant information about its history.\n",
    "\n",
    "> Publish the data as an OKN, using a standards-compliant RDF serialization format such as Turtle or RDF/XML. This will enable other researchers and applications to discover, access, and integrate the data into their own knowledge graphs.\n",
    "\n",
    "> By following these steps, we can create an Open Knowledge Network (OKN) from the scientist's drone data, using existing ontologies and vocabularies to ensure interoperability and semantic richness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages in your notebook by adding the following lines at the beginning of the notebook:\n",
    "import pandas as pd\n",
    "from rdflib import Graph, Literal, BNode, Namespace, RDF, URIRef\n",
    "from rdflib.namespace import DCTERMS, FOAF, XSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|echo: true\n",
    "# I want to load the csv file \"./data/CO2Meter_GPS.csv\" to a pandas data frame.\n",
    "data = pd.read_csv(\"./data/CO2Meter_GPS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|echo: true\n",
    "# I want to print the column headers from the data frame we just imported.\n",
    "# I would also like to print the first five rows of the dat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CO2 (PPM)', ' Latitude', ' Longitude', ' Altitude', ' Air Speed (m/s)',\n",
      "       ' Mode', ' Fixed Satellites', ' Available Satellites', 'voltage',\n",
      "       'current', 'level', 'id'],\n",
      "      dtype='object')\n",
      "   CO2 (PPM)   Latitude   Longitude   Altitude   Air Speed (m/s)       Mode  \\\n",
      "0        395  44.382214  -73.258468      66.12              0.02  STABILIZE   \n",
      "1        394  44.382213  -73.258468      66.12              0.03  STABILIZE   \n",
      "2        394  44.382213  -73.258468      66.13              0.05  STABILIZE   \n",
      "3        394  44.382214  -73.258467      66.16              0.08  STABILIZE   \n",
      "4        395  44.382214  -73.258467      66.19              0.01     GUIDED   \n",
      "\n",
      "    Fixed Satellites   Available Satellites  voltage current level  \\\n",
      "0                  4                     11      0.0    None  None   \n",
      "1                  4                     11      0.0    None  None   \n",
      "2                  4                     11      0.0    None  None   \n",
      "3                  4                     11      0.0    None  None   \n",
      "4                  4                     11      0.0    None  None   \n",
      "\n",
      "             id  \n",
      "0  1.475084e+09  \n",
      "1  1.475084e+09  \n",
      "2  1.475084e+09  \n",
      "3  1.475084e+09  \n",
      "4  1.475084e+09  \n"
     ]
    }
   ],
   "source": [
    "#|echo: true\n",
    "# Print column headers from the data frame\n",
    "print(data.columns)\n",
    "\n",
    "# Print first five rows of the data frame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To map the CSV data to the appropriate classes and properties in the defined ontology, you could follow the following steps:\n",
    "\n",
    "Define the classes and properties in the ontology:\n",
    "Use SOSA Observation class for CO2 measurement data.\n",
    "Use QUDT for defining the unit of measurement for CO2 concentration as PPM.\n",
    "Use OWL-Time for representing the time at which the observation was made.\n",
    "Use SOSA FeatureOfInterest for latitude, longitude, and altitude.\n",
    "Use SOSA Platform for the drone.\n",
    "Use SOSA Sensor for the sensor used to make the observation.\n",
    "Use SOSA ObservableProperty for the observed property, which is CO2 concentration.\n",
    "Use SOSA Result for the result of the observation.\n",
    "Use SOSA Actuation for mode.\n",
    "Map the CSV data to the defined classes and properties:\n",
    "CO2 (PPM) can be mapped to the SOSA ObservableProperty with a unit of measurement defined using QUDT.\n",
    "Latitude, longitude, and altitude can be mapped to the SOSA FeatureOfInterest.\n",
    "The drone can be mapped to the SOSA Platform.\n",
    "The sensor used to make the observation can be mapped to the SOSA Sensor.\n",
    "The observedBy property can be used to link the Observation to the Sensor.\n",
    "Air Speed (m/s) can be mapped to a property of the Observation.\n",
    "The mode can be mapped to the SOSA Actuation.\n",
    "Fixed Satellites and Available Satellites can be mapped to a property of the Platform.\n",
    "Voltage, current, and level are not defined in the ontology and may need to be mapped to a custom property or extension.\n",
    "Use DCAT to describe the dataset:\n",
    "Use DCAT to describe the dataset and link it to the classes and properties in the ontology.\n",
    "Provide metadata such as the creator, publisher, license, and date of publication.\n",
    "By following these steps, you can create an Open Knowledge Network (OKN) using known vocabularies (SOSA, OWL-Time, Prov-o, Dcat) where possible to enable interoperability, and map the CSV data to the appropriate classes and properties in the defined ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|echo: true\n",
    "# Lets start with creating a rdflib graph and the name spaces needed for\n",
    "# KG Construction. Lets define the namespaces needed for the KG including\n",
    "# SOSA, DCAT, QUDT, OWL-Time\n",
    "from rdflib import Graph, Namespace, Literal\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "from datetime import datetime\n",
    "\n",
    "# Define namespaces\n",
    "SOSA = Namespace(\"http://www.w3.org/ns/sosa/\")\n",
    "QUDT = Namespace(\"http://qudt.org/schema/qudt/\")\n",
    "TIME = Namespace(\"http://www.w3.org/2006/time#\")\n",
    "GEO = Namespace(\"http://www.opengis.net/ont/geosparql#\")\n",
    "\n",
    "# Define an RDF Graph\n",
    "g = Graph()\n",
    "\n",
    "# Iterate through the rows of the dataframe\n",
    "for i, row in data.head(5).iterrows():\n",
    "    # Convert Unix timestamp to datetime\n",
    "    timestamp = datetime.fromtimestamp(int(row['id']))\n",
    "    # Define the observation URI\n",
    "    obs_uri = SOSA['obs_{}'.format(i)]\n",
    "    # Define the FeatureOfInterest URI\n",
    "    foi_uri = SOSA['foi_{}'.format(i)]\n",
    "    g.add((foi_uri, RDF.type, SOSA['FeatureOfInterest']))\n",
    "\n",
    "    \n",
    "    # Define the Sensor URI\n",
    "    sensor_uri = SOSA['sensor_{}'.format(i)]\n",
    "    \n",
    "    # Define the Platform URI\n",
    "    platform_uri = SOSA['platform_{}'.format(i)]\n",
    "    \n",
    "    # Define the observed property URI\n",
    "    obs_prop_uri = SOSA['obsProp_CO2']\n",
    "    \n",
    "    # Define the CO2 concentration measurement\n",
    "    obs_value = Literal(row['CO2 (PPM)'], datatype=QUDT['PPM'])\n",
    "    \n",
    "    # Define the latitude, longitude, and altitude\n",
    "    lat = Literal(row[' Latitude'], datatype=XSD['float'])\n",
    "    lon = Literal(row[' Longitude'], datatype=XSD['float'])\n",
    "    alt = Literal(row[' Altitude'], datatype=XSD['float'])\n",
    "    \n",
    "    # Define the geometry URI and WKT literal\n",
    "    geom_uri = foi_uri + '_geom'\n",
    "    geom_wkt = 'POINT({} {} {})'.format(lon, lat, alt)\n",
    "    g.add((geom_uri, RDF.type, GEO['Geometry']))\n",
    "    g.add((geom_uri, GEO['asWKT'], Literal(geom_wkt, datatype=GEO['wktLiteral'])))\n",
    "    \n",
    "    # Add the geometry to the FeatureOfInterest\n",
    "    g.add((foi_uri, GEO['hasGeometry'], geom_uri))\n",
    "    \n",
    "    # Define the air speed\n",
    "    air_speed = Literal(row[' Air Speed (m/s)'], datatype=XSD['float'])\n",
    "    \n",
    "    # Define the mode (STABILIZE or GUIDED)\n",
    "    mode = Literal(row[' Mode'], datatype=XSD['string'])\n",
    "    \n",
    "    # Define the fixed and available satellites\n",
    "    fixed_satellites = Literal(row[' Fixed Satellites'], datatype=XSD['integer'])\n",
    "    avail_satellites = Literal(row[' Available Satellites'], datatype=XSD['integer'])\n",
    "    # Print the values of the variables for the current row\n",
    "    # print(f\"Observation URI: {obs_uri}, Latitude: {lat}, Longitude: {lon}, Altitude: {alt}, Air Speed: {air_speed}, Mode: {mode}, Fixed Satellites: {fixed_satellites}, Available Satellites: {avail_satellites}\")\n",
    "    # Add triples to the graph\n",
    "    g.add((obs_uri, RDF.type, SOSA['Observation']))\n",
    "    g.add((obs_uri, SOSA.observedProperty, obs_prop_uri))\n",
    "    g.add((obs_uri, SOSA.madeBySensor, sensor_uri))\n",
    "    g.add((obs_uri, SOSA.observedBy, platform_uri))\n",
    "    g.add((obs_uri, SOSA.hasResult, obs_uri+'_result'))\n",
    "    g.add((obs_uri, SOSA.phenomenonTime, TIME['Instant_'+str(i)]))\n",
    "    g.add((obs_uri, SOSA.observedAt, foi_uri))\n",
    "    g.add((obs_uri+'_result', RDF.type, SOSA['Result']))\n",
    "    g.add((obs_uri+'_result', SOSA.hasValue, obs_value))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <http://www.w3.org/ns/sosa/> .\n",
      "@prefix ns2: <http://www.opengis.net/ont/geosparql#> .\n",
      "\n",
      "ns1:obs_0 a ns1:Observation ;\n",
      "    ns1:hasResult ns1:obs_0_result ;\n",
      "    ns1:madeBySensor ns1:sensor_0 ;\n",
      "    ns1:observedAt ns1:foi_0 ;\n",
      "    ns1:observedBy ns1:platform_0 ;\n",
      "    ns1:observedProperty ns1:obsProp_CO2 ;\n",
      "    ns1:phenomenonTime <http://www.w3.org/2006/time#Instant_0> .\n",
      "\n",
      "ns1:obs_1 a ns1:Observation ;\n",
      "    ns1:hasResult ns1:obs_1_result ;\n",
      "    ns1:madeBySensor ns1:sensor_1 ;\n",
      "    ns1:observedAt ns1:foi_1 ;\n",
      "    ns1:observedBy ns1:platform_1 ;\n",
      "    ns1:observedProperty ns1:obsProp_CO2 ;\n",
      "    ns1:phenomenonTime <http://www.w3.org/2006/time#Instant_1> .\n",
      "\n",
      "ns1:obs_2 a ns1:Observation ;\n",
      "    ns1:hasResult ns1:obs_2_result ;\n",
      "    ns1:madeBySensor ns1:sensor_2 ;\n",
      "    ns1:observedAt ns1:foi_2 ;\n",
      "    ns1:observedBy ns1:platform_2 ;\n",
      "    ns1:observedProperty ns1:obsProp_CO2 ;\n",
      "    ns1:phenomenonTime <http://www.w3.org/2006/time#Instant_2> .\n",
      "\n",
      "ns1:obs_3 a ns1:Observation ;\n",
      "    ns1:hasResult ns1:obs_3_result ;\n",
      "    ns1:madeBySensor ns1:sensor_3 ;\n",
      "    ns1:observedAt ns1:foi_3 ;\n",
      "    ns1:observedBy ns1:platform_3 ;\n",
      "    ns1:observedProperty ns1:obsProp_CO2 ;\n",
      "    ns1:phenomenonTime <http://www.w3.org/2006/time#Instant_3> .\n",
      "\n",
      "ns1:obs_4 a ns1:Observation ;\n",
      "    ns1:hasResult ns1:obs_4_result ;\n",
      "    ns1:madeBySensor ns1:sensor_4 ;\n",
      "    ns1:observedAt ns1:foi_4 ;\n",
      "    ns1:observedBy ns1:platform_4 ;\n",
      "    ns1:observedProperty ns1:obsProp_CO2 ;\n",
      "    ns1:phenomenonTime <http://www.w3.org/2006/time#Instant_4> .\n",
      "\n",
      "ns1:foi_0 a ns1:FeatureOfInterest ;\n",
      "    ns2:hasGeometry ns1:foi_0_geom .\n",
      "\n",
      "ns1:foi_0_geom a ns2:Geometry ;\n",
      "    ns2:asWKT \"POINT(-73.2584681 44.3822137 66.12)\"^^ns2:wktLiteral .\n",
      "\n",
      "ns1:foi_1 a ns1:FeatureOfInterest ;\n",
      "    ns2:hasGeometry ns1:foi_1_geom .\n",
      "\n",
      "ns1:foi_1_geom a ns2:Geometry ;\n",
      "    ns2:asWKT \"POINT(-73.2584678 44.3822134 66.12)\"^^ns2:wktLiteral .\n",
      "\n",
      "ns1:foi_2 a ns1:FeatureOfInterest ;\n",
      "    ns2:hasGeometry ns1:foi_2_geom .\n",
      "\n",
      "ns1:foi_2_geom a ns2:Geometry ;\n",
      "    ns2:asWKT \"POINT(-73.2584676 44.3822133 66.13)\"^^ns2:wktLiteral .\n",
      "\n",
      "ns1:foi_3 a ns1:FeatureOfInterest ;\n",
      "    ns2:hasGeometry ns1:foi_3_geom .\n",
      "\n",
      "ns1:foi_3_geom a ns2:Geometry ;\n",
      "    ns2:asWKT \"POINT(-73.2584674 44.3822137 66.16)\"^^ns2:wktLiteral .\n",
      "\n",
      "ns1:foi_4 a ns1:FeatureOfInterest ;\n",
      "    ns2:hasGeometry ns1:foi_4_geom .\n",
      "\n",
      "ns1:foi_4_geom a ns2:Geometry ;\n",
      "    ns2:asWKT \"POINT(-73.2584674 44.3822142 66.19)\"^^ns2:wktLiteral .\n",
      "\n",
      "ns1:obs_0_result a ns1:Result ;\n",
      "    ns1:hasValue \"395\"^^<http://qudt.org/schema/qudt/PPM> .\n",
      "\n",
      "ns1:obs_1_result a ns1:Result ;\n",
      "    ns1:hasValue \"394\"^^<http://qudt.org/schema/qudt/PPM> .\n",
      "\n",
      "ns1:obs_2_result a ns1:Result ;\n",
      "    ns1:hasValue \"394\"^^<http://qudt.org/schema/qudt/PPM> .\n",
      "\n",
      "ns1:obs_3_result a ns1:Result ;\n",
      "    ns1:hasValue \"394\"^^<http://qudt.org/schema/qudt/PPM> .\n",
      "\n",
      "ns1:obs_4_result a ns1:Result ;\n",
      "    ns1:hasValue \"395\"^^<http://qudt.org/schema/qudt/PPM> .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Serialize the graph to Turtle format\n",
    "turtle = g.serialize(format='turtle')\n",
    "\n",
    "# Print the Turtle output\n",
    "print(turtle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
